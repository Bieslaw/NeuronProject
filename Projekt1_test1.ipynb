{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e1cb878-5da2-4a15-b73a-7dce723709e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred)**2)\n",
    "\n",
    "def loss_d(y_true, y_pred):\n",
    "    return 2 * y_pred - 2 * y_true\n",
    "\n",
    "def sigm_fun(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigm_d(sigm_val):\n",
    "    return sigm_val * (1 - sigm_val)\n",
    "\n",
    "def relu(x):\n",
    "    return 0 if x < 0 else x\n",
    "def relu_d(relu_val):\n",
    "    return 0 if relu_val <= 0 else 1\n",
    "\n",
    "def softmax(outputs):\n",
    "    exp_outputs = [math.exp(o) for o in outputs]\n",
    "    total = sum(exp_outputs)\n",
    "    return [eo / total for eo in exp_outputs]\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    y_true = int(y_true - 1)\n",
    "    return - (y_true* np.log(y_pred + 1e-10) + (1 - y_true) * np.log(1 - y_pred + 1e-10))\n",
    "\n",
    "def cross_entropy_loss_d(y_true, y_pred):\n",
    "    y_true = int(y_true - 1)\n",
    "    return y_pred - y_true\n",
    "\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, rng, input_dim, activation_f = sigm_fun, activation_f_d = sigm_d):\n",
    "        self.activation_f = activation_f\n",
    "        self.activation_f_d = activation_f_d\n",
    "        weight_list = []\n",
    "        for i in range(input_dim):\n",
    "            weight_list.append(rng.uniform(-1, 1))\n",
    "        self.weights = np.asarray(weight_list)\n",
    "        self.b = rng.uniform(-1, 1)\n",
    "        self.b_grad = 0\n",
    "        self.w_grad = np.zeros(input_dim)\n",
    "        self.out_grad = 0\n",
    "    \n",
    "    def work(self, inputs):\n",
    "        self.x = np.array(inputs)\n",
    "        sum = np.sum(inputs * self.weights) + self.b\n",
    "        self.output = self.activation_f(sum)\n",
    "        return self.output\n",
    "\n",
    "    def x_grad(self, i):\n",
    "        return self.out_grad * self.activation_f_d(self.output) * self.weights[i]\n",
    "\n",
    "    def generate_param_grad(self):\n",
    "        self.w_grad = self.out_grad * self.activation_f_d(self.output) * self.x\n",
    "        self.b_grad = self.out_grad * self.activation_f_d(self.output)\n",
    "        \n",
    "    def update_weights(self, errors, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * errors[i] * self.x[i]\n",
    "            \n",
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self, number_of_neurons_in_layer, hidden_layers, input_dim, number_of_outputs = 1, seed=10):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.layers = []\n",
    "        self.neurons: list[Neuron] = []\n",
    "        layer_1 = [Neuron(self.rng, input_dim) for _ in range(number_of_neurons_in_layer)]\n",
    "        self.layers.append(layer_1)\n",
    "        self.neurons.extend(layer_1)\n",
    "        for i in range(hidden_layers - 1):\n",
    "            current_layer = [Neuron(self.rng, number_of_neurons_in_layer) \n",
    "                             for _ in range(number_of_neurons_in_layer)]\n",
    "            self.neurons.extend(current_layer)\n",
    "            self.layers.append(current_layer)\n",
    "        output_layer = []\n",
    "        for i in range(number_of_outputs):\n",
    "            output_neuron = Neuron(self.rng, number_of_neurons_in_layer, activation_f=lambda x:x, activation_f_d=lambda x:1)\n",
    "            output_layer.append(output_neuron)\n",
    "            self.neurons.append(output_neuron)\n",
    "        self.layers.append(output_layer)\n",
    "                                     \n",
    "    def predict_regre(self, inputs):\n",
    "        outputs = inputs.copy()\n",
    "        for layer in self.layers:\n",
    "            outputs = [neuron.work(outputs) for neuron in layer]\n",
    "        return outputs[0]\n",
    "    \n",
    "    def predict_class(self, inputs):\n",
    "        outputs = inputs.copy()\n",
    "        for layer in self.layers:\n",
    "            outputs = [neuron.work(outputs) for neuron in layer]\n",
    "        probabilitie = sigm_fun(outputs[0])\n",
    "    \n",
    "        return probabilitie\n",
    "\n",
    "    def backprop_single_input(self, input, expected_value):\n",
    "        y_pred = self.predict_regre(input)\n",
    "        error = loss(expected_value, y_pred)\n",
    "        error_d = loss_d(y_pred=y_pred, y_true=expected_value)\n",
    "        output_neuron = self.layers[-1][0]\n",
    "        output_neuron.out_grad = error_d\n",
    "        output_neuron.generate_param_grad()\n",
    "        next_layer = self.layers[-1]\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            for i, neuron in enumerate(layer):\n",
    "                neuron.w_grad = 0\n",
    "                neuron.out_grad = 0\n",
    "                neuron.b_grad = 0\n",
    "                for next_neuron in next_layer:\n",
    "                    neuron.out_grad += next_neuron.x_grad(i)\n",
    "                neuron.generate_param_grad()\n",
    "        return error\n",
    "    \n",
    "    def train_regre(self, X, Y, learning_rate=0.05, epochs = 50, print_logs = False):\n",
    "        n = len(X)\n",
    "        for k in range(epochs):\n",
    "            tot_error = 0\n",
    "            tot_grad = [(0, 0) for neuron in self.neurons]\n",
    "            for x, y in zip(X, Y):\n",
    "                tot_error+=self.backprop_single_input(x, y)\n",
    "                tot_grad = [(grad[0] + neuron.w_grad, grad[1] + neuron.b_grad) \n",
    "                            for grad, neuron in zip(tot_grad, self.neurons)]\n",
    "            tot_error = tot_error/n\n",
    "            for grad, neuron in zip(tot_grad, self.neurons):\n",
    "                neuron.weights -= grad[0] / n * learning_rate\n",
    "                neuron.b -= grad[1] / n * learning_rate\n",
    "            if print_logs:\n",
    "                print(f\"Epoch: {k}, mean loss: {tot_error}\")\n",
    "    \n",
    "    def backprop_binary_input(self, input, expected_value):\n",
    "        y_pred = self.predict_class(input)\n",
    "        error = cross_entropy_loss(expected_value, y_pred)\n",
    "        error_d = cross_entropy_loss_d(y_pred=y_pred, y_true=expected_value)\n",
    "        output_neuron = self.layers[-1][0]\n",
    "        output_neuron.out_grad = error_d\n",
    "        output_neuron.generate_param_grad()\n",
    "        next_layer = self.layers[-1]\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            for i, neuron in enumerate(layer):\n",
    "                neuron.w_grad = 0\n",
    "                neuron.out_grad = 0\n",
    "                neuron.b_grad = 0\n",
    "                for next_neuron in next_layer:\n",
    "                    neuron.out_grad += next_neuron.x_grad(i)\n",
    "                neuron.generate_param_grad()\n",
    "        return error\n",
    "    \n",
    "                \n",
    "    def train_class(self, X, Y, learning_rate=0.05, epochs=50, print_logs = False):\n",
    "        n = len(X)\n",
    "        for k in range(epochs):\n",
    "            tot_error = 0\n",
    "            tot_grad = [(0, 0) for neuron in self.neurons]\n",
    "            for x, y in zip(X, Y):\n",
    "                tot_error+=self.backprop_binary_input(x, y)\n",
    "                tot_grad = [(grad[0] + neuron.w_grad, grad[1] + neuron.b_grad) \n",
    "                            for grad, neuron in zip(tot_grad, self.neurons)]\n",
    "            tot_error = tot_error/n\n",
    "            for grad, neuron in zip(tot_grad, self.neurons):\n",
    "                neuron.weights -= grad[0] / n * learning_rate\n",
    "                neuron.b -= grad[1] / n * learning_rate\n",
    "            if print_logs:\n",
    "                print(f\"Epoch: {k}, mean loss: {tot_error}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00e7b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate_model_regre(model, X, Y):\n",
    "    Y_pred = [model.predict_regre(x) for x in X]\n",
    "    MSE = sum([(y_pred - y)**2 for y_pred, y in zip(Y_pred,Y)]) / len(Y)\n",
    "    return math.sqrt(MSE)\n",
    "\n",
    "\n",
    "def evaluate_model_class(model, X, Y):\n",
    "    Y_pred = [model.predict_regre(x)  for x in X]\n",
    "    MSE = sum([(y_pred - y-1)**2 for y_pred, y in zip(Y_pred,Y)]) / len(Y)\n",
    "    return math.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e893919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.999999204241814)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet(hidden_layers=3,number_of_neurons_in_layer=3,input_dim=3)\n",
    "\n",
    "\n",
    "x = [2,3,6]\n",
    "y = 10\n",
    "net.train_regre([x], [y])\n",
    "net.predict_regre(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf2a3398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, mean loss: 15639.93784010736\n",
      "Epoch: 1, mean loss: 14495.484612534612\n",
      "Epoch: 2, mean loss: 13391.54979638965\n",
      "Epoch: 3, mean loss: 12320.909148506797\n",
      "Epoch: 4, mean loss: 11351.06660639774\n",
      "Epoch: 5, mean loss: 10502.473563488866\n",
      "Epoch: 6, mean loss: 9760.835286254449\n",
      "Epoch: 7, mean loss: 9081.752111564683\n",
      "Epoch: 8, mean loss: 8427.239448132528\n",
      "Epoch: 9, mean loss: 7805.032440610013\n",
      "Epoch: 10, mean loss: 7237.030848222936\n",
      "Epoch: 11, mean loss: 6720.875770205831\n",
      "Epoch: 12, mean loss: 6245.734704869882\n",
      "Epoch: 13, mean loss: 5811.6449946979\n",
      "Epoch: 14, mean loss: 5418.469345234659\n",
      "Epoch: 15, mean loss: 5042.512672945741\n",
      "Epoch: 16, mean loss: 4680.15913939188\n",
      "Epoch: 17, mean loss: 4337.911373736666\n",
      "Epoch: 18, mean loss: 4018.4995473640265\n",
      "Epoch: 19, mean loss: 3723.790273061424\n",
      "Epoch: 20, mean loss: 3454.017864485194\n",
      "Epoch: 21, mean loss: 3207.561357980638\n",
      "Epoch: 22, mean loss: 2982.0764282715595\n",
      "Epoch: 23, mean loss: 2775.776834750826\n",
      "Epoch: 24, mean loss: 2587.807118585323\n",
      "Epoch: 25, mean loss: 2417.424811147267\n",
      "Epoch: 26, mean loss: 2263.4078338448303\n",
      "Epoch: 27, mean loss: 2124.2954688052155\n",
      "Epoch: 28, mean loss: 1998.6308121583538\n",
      "Epoch: 29, mean loss: 1885.016995368358\n",
      "Epoch: 30, mean loss: 1782.1178421185602\n",
      "Epoch: 31, mean loss: 1688.637856406094\n",
      "Epoch: 32, mean loss: 1603.3002025685846\n",
      "Epoch: 33, mean loss: 1524.874030525292\n",
      "Epoch: 34, mean loss: 1452.2789233806332\n",
      "Epoch: 35, mean loss: 1384.699141015553\n",
      "Epoch: 36, mean loss: 1321.6047438694222\n",
      "Epoch: 37, mean loss: 1262.6704671521968\n",
      "Epoch: 38, mean loss: 1207.6682579952962\n",
      "Epoch: 39, mean loss: 1156.3929115307071\n",
      "Epoch: 40, mean loss: 1108.6292778051372\n",
      "Epoch: 41, mean loss: 1064.1457394374497\n",
      "Epoch: 42, mean loss: 1022.6990408879064\n",
      "Epoch: 43, mean loss: 984.0420879658024\n",
      "Epoch: 44, mean loss: 947.9312090274964\n",
      "Epoch: 45, mean loss: 914.1318234023248\n",
      "Epoch: 46, mean loss: 882.4224512060033\n",
      "Epoch: 47, mean loss: 852.5973069994906\n",
      "Epoch: 48, mean loss: 824.4677619519097\n",
      "Epoch: 49, mean loss: 797.8629200284099\n",
      "Epoch: 50, mean loss: 772.6295059567681\n",
      "Epoch: 51, mean loss: 748.6312274641842\n",
      "Epoch: 52, mean loss: 725.7477504468972\n",
      "Epoch: 53, mean loss: 703.8734070966618\n",
      "Epoch: 54, mean loss: 682.9157415977452\n",
      "Epoch: 55, mean loss: 662.7939882003363\n",
      "Epoch: 56, mean loss: 643.4375719159056\n",
      "Epoch: 57, mean loss: 624.7847149496075\n",
      "Epoch: 58, mean loss: 606.7812120660756\n",
      "Epoch: 59, mean loss: 589.3794033949257\n",
      "Epoch: 60, mean loss: 572.53733435734\n",
      "Epoch: 61, mean loss: 556.2180652635157\n",
      "Epoch: 62, mean loss: 540.3890865316912\n",
      "Epoch: 63, mean loss: 525.0218057141878\n",
      "Epoch: 64, mean loss: 510.09108821380374\n",
      "Epoch: 65, mean loss: 495.5748449520008\n",
      "Epoch: 66, mean loss: 481.4536645414113\n",
      "Epoch: 67, mean loss: 467.7104876843924\n",
      "Epoch: 68, mean loss: 454.33032148877334\n",
      "Epoch: 69, mean loss: 441.2999925861106\n",
      "Epoch: 70, mean loss: 428.60793921294453\n",
      "Epoch: 71, mean loss: 416.2440420540621\n",
      "Epoch: 72, mean loss: 404.19949106360133\n",
      "Epoch: 73, mean loss: 392.46668151468054\n",
      "Epoch: 74, mean loss: 381.0391287218011\n",
      "Epoch: 75, mean loss: 369.91138862488253\n",
      "Epoch: 76, mean loss: 359.07897149384706\n",
      "Epoch: 77, mean loss: 348.538238478302\n",
      "Epoch: 78, mean loss: 338.2862750666832\n",
      "Epoch: 79, mean loss: 328.32074081064246\n",
      "Epoch: 80, mean loss: 318.63969982699984\n",
      "Epoch: 81, mean loss: 309.2414406254699\n",
      "Epoch: 82, mean loss: 300.12429607229274\n",
      "Epoch: 83, mean loss: 291.2864745921459\n",
      "Epoch: 84, mean loss: 282.7259122762389\n",
      "Epoch: 85, mean loss: 274.4401529469501\n",
      "Epoch: 86, mean loss: 266.4262600828478\n",
      "Epoch: 87, mean loss: 258.6807614264025\n",
      "Epoch: 88, mean loss: 251.1996245065984\n",
      "Epoch: 89, mean loss: 243.97825943495397\n",
      "Epoch: 90, mean loss: 237.01154422205286\n",
      "Epoch: 91, mean loss: 230.2938674316375\n",
      "Epoch: 92, mean loss: 223.819183091448\n",
      "Epoch: 93, mean loss: 217.58107324539043\n",
      "Epoch: 94, mean loss: 211.57281420466387\n",
      "Epoch: 95, mean loss: 205.78744331088947\n",
      "Epoch: 96, mean loss: 200.21782377208376\n",
      "Epoch: 97, mean loss: 194.85670581546879\n",
      "Epoch: 98, mean loss: 189.6967829891447\n",
      "Epoch: 99, mean loss: 184.7307429266569\n",
      "Epoch: 100, mean loss: 179.95131226649588\n",
      "Epoch: 101, mean loss: 175.35129570228094\n",
      "Epoch: 102, mean loss: 170.9236093422726\n",
      "Epoch: 103, mean loss: 166.66130869353506\n",
      "Epoch: 104, mean loss: 162.5576116705698\n",
      "Epoch: 105, mean loss: 158.60591707314416\n",
      "Epoch: 106, mean loss: 154.79981899397714\n",
      "Epoch: 107, mean loss: 151.13311761260306\n",
      "Epoch: 108, mean loss: 147.59982681387552\n",
      "Epoch: 109, mean loss: 144.19417904331948\n",
      "Epoch: 110, mean loss: 140.91062778064475\n",
      "Epoch: 111, mean loss: 137.74384797981577\n",
      "Epoch: 112, mean loss: 134.6887347909209\n",
      "Epoch: 113, mean loss: 131.74040084682335\n",
      "Epoch: 114, mean loss: 128.89417236692523\n",
      "Epoch: 115, mean loss: 126.14558430166151\n",
      "Epoch: 116, mean loss: 123.49037471477179\n",
      "Epoch: 117, mean loss: 120.9244785759701\n",
      "Epoch: 118, mean loss: 118.44402111432522\n",
      "Epoch: 119, mean loss: 116.04531086236577\n",
      "Epoch: 120, mean loss: 113.72483250256117\n",
      "Epoch: 121, mean loss: 111.47923961124681\n",
      "Epoch: 122, mean loss: 109.30534738018429\n",
      "Epoch: 123, mean loss: 107.20012538264\n",
      "Epoch: 124, mean loss: 105.16069043903416\n",
      "Epoch: 125, mean loss: 103.18429962674819\n",
      "Epoch: 126, mean loss: 101.26834346948982\n",
      "Epoch: 127, mean loss: 99.41033933358938\n",
      "Epoch: 128, mean loss: 97.60792505166211\n",
      "Epoch: 129, mean loss: 95.85885278810825\n",
      "Epoch: 130, mean loss: 94.16098315584784\n",
      "Epoch: 131, mean loss: 92.51227958942465\n",
      "Epoch: 132, mean loss: 90.91080297605492\n",
      "Epoch: 133, mean loss: 89.35470654327531\n",
      "Epoch: 134, mean loss: 87.84223099949627\n",
      "Epoch: 135, mean loss: 86.37169992187461\n",
      "Epoch: 136, mean loss: 84.94151538448132\n",
      "Epoch: 137, mean loss: 83.5501538186405\n",
      "Epoch: 138, mean loss: 82.19616209653225\n",
      "Epoch: 139, mean loss: 80.87815382862513\n",
      "Epoch: 140, mean loss: 79.59480586519255\n",
      "Epoch: 141, mean loss: 78.34485499203754\n",
      "Epoch: 142, mean loss: 77.1270948105567\n",
      "Epoch: 143, mean loss: 75.94037279241059\n",
      "Epoch: 144, mean loss: 74.78358749928647\n",
      "Epoch: 145, mean loss: 73.65568595852973\n",
      "Epoch: 146, mean loss: 72.55566118577579\n",
      "Epoch: 147, mean loss: 71.48254984609144\n",
      "Epoch: 148, mean loss: 70.4354300455527\n",
      "Epoch: 149, mean loss: 69.41341924561108\n",
      "Epoch: 150, mean loss: 68.41567229303459\n",
      "Epoch: 151, mean loss: 67.44137955864257\n",
      "Epoch: 152, mean loss: 66.48976517848021\n",
      "Epoch: 153, mean loss: 65.5600853914925\n",
      "Epoch: 154, mean loss: 64.65162696815666\n",
      "Epoch: 155, mean loss: 63.76370572491033\n",
      "Epoch: 156, mean loss: 62.89566511957614\n",
      "Epoch: 157, mean loss: 62.04687492331326\n",
      "Epoch: 158, mean loss: 61.21672996494439\n",
      "Epoch: 159, mean loss: 60.40464894379371\n",
      "Epoch: 160, mean loss: 59.61007330743138\n",
      "Epoch: 161, mean loss: 58.83246619096382\n",
      "Epoch: 162, mean loss: 58.0713114147209\n",
      "Epoch: 163, mean loss: 57.326112537385015\n",
      "Epoch: 164, mean loss: 56.59639196177289\n",
      "Epoch: 165, mean loss: 55.8816900906347\n",
      "Epoch: 166, mean loss: 55.181564529957804\n",
      "Epoch: 167, mean loss: 54.49558933737773\n",
      "Epoch: 168, mean loss: 53.823354313386155\n",
      "Epoch: 169, mean loss: 53.16446433311063\n",
      "Epoch: 170, mean loss: 52.51853871649811\n",
      "Epoch: 171, mean loss: 51.885210634792685\n",
      "Epoch: 172, mean loss: 51.2641265512371\n",
      "Epoch: 173, mean loss: 50.65494569396366\n",
      "Epoch: 174, mean loss: 50.057339559069604\n",
      "Epoch: 175, mean loss: 49.47099144189267\n",
      "Epoch: 176, mean loss: 48.89559599453307\n",
      "Epoch: 177, mean loss: 48.3308588076782\n",
      "Epoch: 178, mean loss: 47.77649601482317\n",
      "Epoch: 179, mean loss: 47.23223391699809\n",
      "Epoch: 180, mean loss: 46.69780862615103\n",
      "Epoch: 181, mean loss: 46.17296572537716\n",
      "Epoch: 182, mean loss: 45.657459944229416\n",
      "Epoch: 183, mean loss: 45.15105484740975\n",
      "Epoch: 184, mean loss: 44.6535225352121\n",
      "Epoch: 185, mean loss: 44.16464335416597\n",
      "Epoch: 186, mean loss: 43.68420561643174\n",
      "Epoch: 187, mean loss: 43.21200532660398\n",
      "Epoch: 188, mean loss: 42.74784591470011\n",
      "Epoch: 189, mean loss: 42.29153797424384\n",
      "Epoch: 190, mean loss: 41.84289900449531\n",
      "Epoch: 191, mean loss: 41.40175315603063\n",
      "Epoch: 192, mean loss: 40.96793097902572\n",
      "Epoch: 193, mean loss: 40.541269173764775\n",
      "Epoch: 194, mean loss: 40.12161034304803\n",
      "Epoch: 195, mean loss: 39.708802746334726\n",
      "Epoch: 196, mean loss: 39.302700055606834\n",
      "Epoch: 197, mean loss: 38.903161113084494\n",
      "Epoch: 198, mean loss: 38.51004969105345\n",
      "Epoch: 199, mean loss: 38.123234254184155\n",
      "RMSE on train data 6.143499631710085\n",
      "RMSE on test data 25.20389178419844\n"
     ]
    }
   ],
   "source": [
    "train_data = np.genfromtxt('./projekt1/regression/data.activation.train.100.csv', delimiter=',')\n",
    "test_data = np.genfromtxt('./projekt1/regression/data.activation.test.100.csv', delimiter=',')\n",
    "X_train = train_data[1:, 0]\n",
    "Y_train = train_data[1:, 1]\n",
    "X_test = test_data[1:, 0]\n",
    "Y_test = test_data[1:, 1]\n",
    "\n",
    "net = NeuralNet(hidden_layers=2,number_of_neurons_in_layer=30,input_dim=1)\n",
    "net.train_regre(X_train, Y_train, learning_rate=0.003, epochs=200, print_logs=True)\n",
    "\n",
    "print(f\"RMSE on train data {evaluate_model_regre(net, X_train, Y_train)}\")\n",
    "print(f\"RMSE on test data {evaluate_model_regre(net, X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9248d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1802e0144a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ind = np.argsort(X_train)\n",
    "plt.plot(X_test, Y_test, label = 'test')\n",
    "Y_pred = [net.predict_regre(x) for x in X_test]\n",
    "plt.plot(X_test, Y_pred, label = 'pred')\n",
    "plt.plot(X_train[ind], Y_train[ind], label = 'train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac57271",
   "metadata": {},
   "source": [
    "# Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8fab11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, mean loss: 1.7914715490900974\n",
      "Epoch: 1, mean loss: 1.781857459673902\n",
      "Epoch: 2, mean loss: 1.7722632822753517\n",
      "Epoch: 3, mean loss: 1.7626893545247666\n",
      "Epoch: 4, mean loss: 1.7531360181226296\n",
      "Epoch: 5, mean loss: 1.7436036188176802\n",
      "Epoch: 6, mean loss: 1.7340925063818784\n",
      "Epoch: 7, mean loss: 1.72460303458211\n",
      "Epoch: 8, mean loss: 1.7151355611485644\n",
      "Epoch: 9, mean loss: 1.7056904477396655\n",
      "Epoch: 10, mean loss: 1.696268059903492\n",
      "Epoch: 11, mean loss: 1.6868687670355689\n",
      "Epoch: 12, mean loss: 1.677492942332955\n",
      "Epoch: 13, mean loss: 1.6681409627445278\n",
      "Epoch: 14, mean loss: 1.6588132089173786\n",
      "Epoch: 15, mean loss: 1.6495100651392332\n",
      "Epoch: 16, mean loss: 1.6402319192768113\n",
      "Epoch: 17, mean loss: 1.630979162710031\n",
      "Epoch: 18, mean loss: 1.6217521902620007\n",
      "Epoch: 19, mean loss: 1.6125514001246952\n",
      "Epoch: 20, mean loss: 1.6033771937802432\n",
      "Epoch: 21, mean loss: 1.5942299759177798\n",
      "Epoch: 22, mean loss: 1.5851101543457475\n",
      "Epoch: 23, mean loss: 1.5760181398996342\n",
      "Epoch: 24, mean loss: 1.5669543463450326\n",
      "Epoch: 25, mean loss: 1.557919190276008\n",
      "Epoch: 26, mean loss: 1.5489130910086921\n",
      "Epoch: 27, mean loss: 1.5399364704700702\n",
      "Epoch: 28, mean loss: 1.530989753081905\n",
      "Epoch: 29, mean loss: 1.5220733656397814\n",
      "Epoch: 30, mean loss: 1.5131877371872084\n",
      "Epoch: 31, mean loss: 1.504333298884787\n",
      "Epoch: 32, mean loss: 1.495510483874398\n",
      "Epoch: 33, mean loss: 1.4867197271384054\n",
      "Epoch: 34, mean loss: 1.4779614653538835\n",
      "Epoch: 35, mean loss: 1.4692361367418454\n",
      "Epoch: 36, mean loss: 1.4605441809114925\n",
      "Epoch: 37, mean loss: 1.4518860386995274\n",
      "Epoch: 38, mean loss: 1.4432621520044946\n",
      "Epoch: 39, mean loss: 1.434672963616257\n",
      "Epoch: 40, mean loss: 1.4261189170405928\n",
      "Epoch: 41, mean loss: 1.4176004563190006\n",
      "Epoch: 42, mean loss: 1.4091180258437515\n",
      "Epoch: 43, mean loss: 1.4006720701682738\n",
      "Epoch: 44, mean loss: 1.3922630338129445\n",
      "Epoch: 45, mean loss: 1.383891361066377\n",
      "Epoch: 46, mean loss: 1.375557495782314\n",
      "Epoch: 47, mean loss: 1.3672618811722248\n",
      "Epoch: 48, mean loss: 1.3590049595937317\n",
      "Epoch: 49, mean loss: 1.3507871723350109\n",
      "Epoch: 50, mean loss: 1.342608959395293\n",
      "Epoch: 51, mean loss: 1.3344707592616185\n",
      "Epoch: 52, mean loss: 1.3263730086820233\n",
      "Epoch: 53, mean loss: 1.3183161424353276\n",
      "Epoch: 54, mean loss: 1.3103005930976963\n",
      "Epoch: 55, mean loss: 1.302326790806192\n",
      "Epoch: 56, mean loss: 1.2943951630195045\n",
      "Epoch: 57, mean loss: 1.2865061342760966\n",
      "Epoch: 58, mean loss: 1.2786601259499757\n",
      "Epoch: 59, mean loss: 1.2708575560043294\n",
      "Epoch: 60, mean loss: 1.2630988387432927\n",
      "Epoch: 61, mean loss: 1.2553843845620813\n",
      "Epoch: 62, mean loss: 1.2477145996957677\n",
      "Epoch: 63, mean loss: 1.2400898859669731\n",
      "Epoch: 64, mean loss: 1.2325106405327677\n",
      "Epoch: 65, mean loss: 1.2249772556310576\n",
      "Epoch: 66, mean loss: 1.2174901183267697\n",
      "Epoch: 67, mean loss: 1.210049610258133\n",
      "Epoch: 68, mean loss: 1.2026561073833912\n",
      "Epoch: 69, mean loss: 1.1953099797282305\n",
      "Epoch: 70, mean loss: 1.1880115911342892\n",
      "Epoch: 71, mean loss: 1.1807612990090484\n",
      "Epoch: 72, mean loss: 1.1735594540774608\n",
      "Epoch: 73, mean loss: 1.1664064001356433\n",
      "Epoch: 74, mean loss: 1.1593024738069821\n",
      "Epoch: 75, mean loss: 1.152248004300993\n",
      "Epoch: 76, mean loss: 1.1452433131752822\n",
      "Epoch: 77, mean loss: 1.1382887141009552\n",
      "Epoch: 78, mean loss: 1.1313845126318167\n",
      "Epoch: 79, mean loss: 1.1245310059777112\n",
      "Epoch: 80, mean loss: 1.1177284827823497\n",
      "Epoch: 81, mean loss: 1.1109772229059502\n",
      "Epoch: 82, mean loss: 1.104277497213048\n",
      "Epoch: 83, mean loss: 1.097629567365791\n",
      "Epoch: 84, mean loss: 1.0910336856230634\n",
      "Epoch: 85, mean loss: 1.0844900946457439\n",
      "Epoch: 86, mean loss: 1.0779990273084261\n",
      "Epoch: 87, mean loss: 1.071560706517903\n",
      "Epoch: 88, mean loss: 1.0651753450387036\n",
      "Epoch: 89, mean loss: 1.0588431453259923\n",
      "Epoch: 90, mean loss: 1.0525642993660822\n",
      "Epoch: 91, mean loss: 1.0463389885248555\n",
      "Epoch: 92, mean loss: 1.0401673834043232\n",
      "Epoch: 93, mean loss: 1.034049643707583\n",
      "Epoch: 94, mean loss: 1.027985918112398\n",
      "Epoch: 95, mean loss: 1.0219763441536052\n",
      "Epoch: 96, mean loss: 1.0160210481145697\n",
      "Epoch: 97, mean loss: 1.0101201449278532\n",
      "Epoch: 98, mean loss: 1.0042737380852795\n",
      "Epoch: 99, mean loss: 0.9984819195575371\n",
      "Epoch: 100, mean loss: 0.992744769723475\n",
      "Epoch: 101, mean loss: 0.9870623573091838\n",
      "Epoch: 102, mean loss: 0.9814347393369863\n",
      "Epoch: 103, mean loss: 0.9758619610844178\n",
      "Epoch: 104, mean loss: 0.9703440560532495\n",
      "Epoch: 105, mean loss: 0.9648810459486187\n",
      "Epoch: 106, mean loss: 0.9594729406682816\n",
      "Epoch: 107, mean loss: 0.9541197383020134\n",
      "Epoch: 108, mean loss: 0.9488214251411321\n",
      "Epoch: 109, mean loss: 0.9435779756981362\n",
      "Epoch: 110, mean loss: 0.9383893527363967\n",
      "Epoch: 111, mean loss: 0.9332555073098565\n",
      "Epoch: 112, mean loss: 0.9281763788126425\n",
      "Epoch: 113, mean loss: 0.923151895038501\n",
      "Epoch: 114, mean loss: 0.9181819722499344\n",
      "Epoch: 115, mean loss: 0.9132665152569218\n",
      "Epoch: 116, mean loss: 0.9084054175050457\n",
      "Epoch: 117, mean loss: 0.9035985611728923\n",
      "Epoch: 118, mean loss: 0.8988458172785226\n",
      "Epoch: 119, mean loss: 0.8941470457948212\n",
      "Epoch: 120, mean loss: 0.8895020957735269\n",
      "Epoch: 121, mean loss: 0.8849108054776984\n",
      "Epoch: 122, mean loss: 0.8803730025223971\n",
      "Epoch: 123, mean loss: 0.8758885040233296\n",
      "Epoch: 124, mean loss: 0.8714571167531857\n",
      "Epoch: 125, mean loss: 0.8670786373054039\n",
      "Epoch: 126, mean loss: 0.862752852265083\n",
      "Epoch: 127, mean loss: 0.8584795383867457\n",
      "Epoch: 128, mean loss: 0.8542584627786511\n",
      "Epoch: 129, mean loss: 0.8500893830933549\n",
      "Epoch: 130, mean loss: 0.8459720477241985\n",
      "Epoch: 131, mean loss: 0.8419061960074061\n",
      "Epoch: 132, mean loss: 0.8378915584294657\n",
      "Epoch: 133, mean loss: 0.833927856839462\n",
      "Epoch: 134, mean loss: 0.8300148046660332\n",
      "Epoch: 135, mean loss: 0.8261521071386038\n",
      "Epoch: 136, mean loss: 0.82233946151257\n",
      "Epoch: 137, mean loss: 0.8185765572980875\n",
      "Epoch: 138, mean loss: 0.814863076492133\n",
      "Epoch: 139, mean loss: 0.811198693813485\n",
      "Epoch: 140, mean loss: 0.8075830769403108\n",
      "Epoch: 141, mean loss: 0.8040158867500016\n",
      "Epoch: 142, mean loss: 0.8004967775609392\n",
      "Epoch: 143, mean loss: 0.7970253973758551\n",
      "Epoch: 144, mean loss: 0.7936013881264752\n",
      "Epoch: 145, mean loss: 0.7902243859191047\n",
      "Epoch: 146, mean loss: 0.7868940212808639\n",
      "Epoch: 147, mean loss: 0.7836099194062567\n",
      "Epoch: 148, mean loss: 0.7803717004037654\n",
      "Epoch: 149, mean loss: 0.7771789795421892\n",
      "Epoch: 150, mean loss: 0.7740313674964316\n",
      "Epoch: 151, mean loss: 0.770928470592459\n",
      "Epoch: 152, mean loss: 0.7678698910511641\n",
      "Epoch: 153, mean loss: 0.7648552272308669\n",
      "Epoch: 154, mean loss: 0.7618840738682029\n",
      "Epoch: 155, mean loss: 0.7589560223171584\n",
      "Epoch: 156, mean loss: 0.7560706607860116\n",
      "Epoch: 157, mean loss: 0.7532275745719599\n",
      "Epoch: 158, mean loss: 0.7504263462932209\n",
      "Epoch: 159, mean loss: 0.747666556118399\n",
      "Epoch: 160, mean loss: 0.7449477819929213\n",
      "Epoch: 161, mean loss: 0.7422695998623681\n",
      "Epoch: 162, mean loss: 0.7396315838925155\n",
      "Epoch: 163, mean loss: 0.7370333066859264\n",
      "Epoch: 164, mean loss: 0.7344743394949488\n",
      "Epoch: 165, mean loss: 0.7319542524309632\n",
      "Epoch: 166, mean loss: 0.7294726146697569\n",
      "Epoch: 167, mean loss: 0.7270289946529\n",
      "Epoch: 168, mean loss: 0.7246229602850077\n",
      "Epoch: 169, mean loss: 0.7222540791267923\n",
      "Epoch: 170, mean loss: 0.7199219185838107\n",
      "Epoch: 171, mean loss: 0.7176260460908166\n",
      "Epoch: 172, mean loss: 0.7153660292916545\n",
      "Epoch: 173, mean loss: 0.7131414362146277\n",
      "Epoch: 174, mean loss: 0.710951835443276\n",
      "Epoch: 175, mean loss: 0.7087967962825324\n",
      "Epoch: 176, mean loss: 0.7066758889202045\n",
      "Epoch: 177, mean loss: 0.7045886845837578\n",
      "Epoch: 178, mean loss: 0.7025347556923822\n",
      "Epoch: 179, mean loss: 0.7005136760043161\n",
      "Epoch: 180, mean loss: 0.6985250207594345\n",
      "Epoch: 181, mean loss: 0.696568366817087\n",
      "Epoch: 182, mean loss: 0.6946432927892044\n",
      "Epoch: 183, mean loss: 0.6927493791686787\n",
      "Epoch: 184, mean loss: 0.6908862084530419\n",
      "Epoch: 185, mean loss: 0.6890533652634621\n",
      "Epoch: 186, mean loss: 0.6872504364590967\n",
      "Epoch: 187, mean loss: 0.6854770112468305\n",
      "Epoch: 188, mean loss: 0.6837326812864468\n",
      "Epoch: 189, mean loss: 0.6820170407912702\n",
      "Epoch: 190, mean loss: 0.6803296866243432\n",
      "Epoch: 191, mean loss: 0.6786702183901754\n",
      "Epoch: 192, mean loss: 0.6770382385221407\n",
      "Epoch: 193, mean loss: 0.6754333523655716\n",
      "Epoch: 194, mean loss: 0.6738551682566215\n",
      "Epoch: 195, mean loss: 0.67230329759697\n",
      "Epoch: 196, mean loss: 0.6707773549244246\n",
      "Epoch: 197, mean loss: 0.6692769579795161\n",
      "Epoch: 198, mean loss: 0.6678017277681434\n",
      "Epoch: 199, mean loss: 0.6663512886203604\n",
      "RMSE on train data 1.8607064561551367\n",
      "RMSE on train data 1.8209574056176094\n"
     ]
    }
   ],
   "source": [
    "train_data = np.genfromtxt('./projekt1/classification/data.simple.train.100.csv', delimiter=',')\n",
    "test_data = np.genfromtxt('./projekt1/classification/data.simple.test.100.csv', delimiter=',')\n",
    "X_train = train_data[1:, :2]\n",
    "Y_train = train_data[1:, 2]\n",
    "X_test = test_data[1:, :2]\n",
    "Y_test = test_data[1:, 2]\n",
    "\n",
    "net = NeuralNet(hidden_layers=2,number_of_neurons_in_layer=30,input_dim=2, number_of_outputs = 1)\n",
    "net.train_class(X_train, Y_train, learning_rate=0.003, epochs=200, print_logs=True)\n",
    "\n",
    "print(f\"RMSE on train data {evaluate_model_class(net, X_train, Y_train)}\")\n",
    "print(f\"RMSE on train data {evaluate_model_class(net, X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8f742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b44f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1eeee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
